{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9kIqgkMgEXab"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import tree, ensemble, datasets\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) Use the breast cancer data set from Homework 0 to create a training set.\n",
    "Recall that the label is 0 if the patient has breast cancer and 1 otherwise.\n",
    "Compute the base rate of cancer occurrence over the entire data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37258347978910367"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer = datasets.load_breast_cancer()\n",
    "df = pd.DataFrame(cancer.data, columns = cancer.feature_names)\n",
    "df['target'] = cancer.target\n",
    "target = df['target']\n",
    "q = np.where(target == 0)[0]\n",
    "baserate = len(q)/len(df)\n",
    "baserate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**On random seeds:** Many functions in scikit-learn, including models as well as utilities,\n",
    "use randomization. For ease of grading, we will fix a random seed (we will use 101 throughout)\n",
    "so as to make behavior deterministic. This can generally be done by passing in `random_state=101` to\n",
    "the function; please consult documentation if unsure. Note to peer graders: this is purely for grading\n",
    "convenience. Do not penalize harshly if the random seed has not been set properly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) The goal is to build a decision tree that, based on the other features in the set,\n",
    "predicts whether or not a patient has cancer.  So this is a classification problem.\n",
    "Using tree.DecisionTreeClassifier and other functions in the scikit-learn library, one can\n",
    "build a decision tree and calculate both its training accuracy when fitted to the entire data set\n",
    "as well as its accuracy using 10-fold cross validation (which gives a better idea of true accuracy).\n",
    "\n",
    "Vary the depth of your decision tree (use max_depth = $1, 2, \\dots, 10$) and plot both training\n",
    "accuracy and cross-validated accuracy (as a function of the depth, on the x-axis). Use 101 as your\n",
    "random seed. Plot both curves on the same plot and use a legend to label them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "get_params",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\envs\\Master-HW0\\lib\\site-packages\\sklearn\\utils\\__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 94\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     95\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'get_params'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-67-be3a98026abd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mparameter_range\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mcancer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;31m# Calculate accuracy on training and test set using the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;31m# gamma parameter with 5-fold cross validation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Master-HW0\\lib\\site-packages\\sklearn\\utils\\__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m     94\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setstate__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: get_params"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import validation_curve\n",
    "X = cancer.data\n",
    "Y = cancer.target\n",
    "\n",
    "clf = DecisionTreeClassifier(random_state=101)\n",
    "model = clf.fit(X,Y)\n",
    "#text_representation = tree.export_text(clf)\n",
    "#print(text_representation)\n",
    "# Setting the range for the parameter (from 1 to 10)\n",
    "parameter_range = np.arange(1, 10, 1)\n",
    "\n",
    "\n",
    "# Calculate accuracy on training and test set using the\n",
    "# gamma parameter with 5-fold cross validation\n",
    "train_score, test_score = validation_curve(DecisionTreeClassifier(), X, Y,\n",
    "                                       param_name = \"n_estimators\",\n",
    "                                       param_range = parameter_range,\n",
    "                                        cv = 10, scoring = \"accuracy\")\n",
    " \n",
    "# Calculating mean and standard deviation of training score\n",
    "mean_train_score = np.mean(train_score, axis = 1)\n",
    "std_train_score = np.std(train_score, axis = 1)\n",
    " \n",
    "# Calculating mean and standard deviation of testing score\n",
    "mean_test_score = np.mean(test_score, axis = 1)\n",
    "std_test_score = np.std(test_score, axis = 1)\n",
    " \n",
    "# Plot mean accuracy scores for training and testing scores\n",
    "plt.plot(parameter_range, mean_train_score,\n",
    "     label = \"Training Score\", color = 'b')\n",
    "plt.plot(parameter_range, mean_test_score,\n",
    "   label = \"Cross Validation Score\", color = 'g')\n",
    " \n",
    "# Creating the plot\n",
    "plt.title(\"Validation Curve with KNN Classifier\")\n",
    "plt.xlabel(\"Number of Neighbours\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.tight_layout()\n",
    "plt.legend(loc = 'best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) Now try the random forest classifier of the scikit-learn library and use the best\n",
    "depth you get from (b) as max_depth. Vary the number of trees in the forest via the parameter\n",
    "n_estimators and plot its 10-fold cross-validated accuracy (use n_estimators = $1, 2, \\dots, 20$).\n",
    "Again, use 101 as your random seed. Do you see an improvement using random forests versus\n",
    "using a single tree? (Note: use the n_estimators=1 result as the result for a single tree.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth_range = list(range(1, 10))# List to store each value of max_depth:\n",
    "accuracy = []for depth in max_depth_range:\n",
    "    \n",
    "    clf = DecisionTreeClassifier(max_depth = depth, \n",
    "                             random_state = 0)\n",
    "    clf.fit(X_train, Y_train)    score = clf.score(X_test, Y_test)\n",
    "    accuracy.append(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(d) Using the method for building a decision tree you used in part (b), build a tree\n",
    "but randomly hold out a $.2$,$.4$,$.6$, and $.8$ fraction of the data set (so you \n",
    "will need to build 4 different trees for each depth value). Use 101 as your random seed for both\n",
    "the train-test split as well as the decision tree.\n",
    "For each fraction held out, plot a curve of the test accuracy (the accuracy on the held-out\n",
    "set) against depth. You should have four curves. Plot them all on the same plot and use\n",
    "a legend to label them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "hw1-solution.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
